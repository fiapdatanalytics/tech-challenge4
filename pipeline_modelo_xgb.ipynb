{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPlvqUdcRNGGA22RsQ5gfhJ",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/fiapdatanalytics/tech-challenge4/blob/main/pipeline_modelo_xgb.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zOC8lpyjm3C8",
        "outputId": "28eb0748-d967-4d6b-f4af-41194c893f21"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "DataFrame e mapas JSON carregados com sucesso.\n",
            "Coluna 'classificacao_peso_corporal' transformada com sucesso.\n",
            "Coluna 'mtrans' transformada com sucesso.\n",
            "Coluna 'caec' transformada com sucesso.\n",
            "Coluna 'calc' transformada com sucesso.\n",
            "Coluna 'genero' transformada com sucesso.\n",
            "Coluna 'historico_familiar' transformada com sucesso.\n",
            "Coluna 'favc' transformada com sucesso.\n",
            "Coluna 'fumante' transformada com sucesso.\n",
            "Coluna 'scc' transformada com sucesso.\n",
            "Pré-processamentos iniciais aplicados e df_processado criado.\n",
            "Dados preparados: X, y definidos, y codificado e dividido em treino/teste.\n",
            "Pipelines de pré-processamento e o modelo XGBoost definidos e combinados no pipeline completo.\n",
            "Iniciando o treinamento do pipeline XGBoost completo...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/xgboost/training.py:199: UserWarning: [14:54:36] WARNING: /workspace/src/learner.cc:790: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  bst.update(dtrain, iteration=i, fobj=obj)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Acurácia do Pipeline XGBoost: 82.98%\n",
            "\n",
            "Relatório de Classificação:\n",
            "                   precision    recall  f1-score   support\n",
            "\n",
            " obesidade_tipo_1       0.78      0.86      0.82        70\n",
            " obesidade_tipo_2       0.89      0.92      0.90        60\n",
            " obesidade_tipo_3       0.98      1.00      0.99        65\n",
            "peso_insuficiente       0.84      0.89      0.86        54\n",
            "      peso_normal       0.68      0.72      0.70        58\n",
            " sobrepeso_tipo_1       0.84      0.72      0.78        58\n",
            " sobrepeso_tipo_2       0.80      0.67      0.73        58\n",
            "\n",
            "         accuracy                           0.83       423\n",
            "        macro avg       0.83      0.83      0.83       423\n",
            "     weighted avg       0.83      0.83      0.83       423\n",
            "\n",
            "\n",
            "Pipeline de pré-processamento e modelagem concluído!\n",
            "Salvando artefatos...\n",
            "Artefatos salvos com sucesso!\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import re\n",
        "import json\n",
        "import requests\n",
        "from sklearn.base import BaseEstimator, TransformerMixin\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import (\n",
        "    StandardScaler,\n",
        "    OrdinalEncoder,\n",
        "    OneHotEncoder,\n",
        "    LabelEncoder\n",
        ")\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from xgboost import XGBClassifier\n",
        "from sklearn.metrics import accuracy_score, classification_report\n",
        "import joblib\n",
        "\n",
        "#funcoes utilizadas\n",
        "\n",
        "def renomear_colunas(df: pd.DataFrame, mapa_renomeacao: dict = None) -> pd.DataFrame:\n",
        "    \"\"\"\n",
        "    Renomeia as colunas de um DataFrame utilizando um dicionário fornecido\n",
        "    ou aplicando um padrão de formatação (minúsculas, espaços por '_').\n",
        "    Retorna o DataFrame com as colunas renomeadas.\n",
        "    \"\"\"\n",
        "    colunas_originais = df.columns.tolist()\n",
        "    df_modificado = df.copy()\n",
        "\n",
        "    if mapa_renomeacao:\n",
        "        if any(col in mapa_renomeacao for col in colunas_originais):\n",
        "            df_modificado.rename(columns=mapa_renomeacao, inplace=True)\n",
        "        else:\n",
        "            print('Não foi possível realizar a alteração dos nomes das colunas. Rever arquivo de entrada.')\n",
        "    else:\n",
        "        print('Não foi possível realizar a alteração dos nomes das colunas. Rever arquivo de entrada.')\n",
        "\n",
        "    return df_modificado\n",
        "\n",
        "def transformar_valores_string(df: pd.DataFrame, coluna: str, mapa_transformacao: dict):\n",
        "    \"\"\"\n",
        "    Transforma os valores de uma coluna do tipo string para string utilizando um mapeamento.\n",
        "    Modifica o DataFrame inplace.\n",
        "    \"\"\"\n",
        "    if coluna not in df.columns:\n",
        "        print(f\"Erro: A coluna '{coluna}' não existe no DataFrame.\")\n",
        "        return\n",
        "\n",
        "    if df[coluna].dtype != 'object':\n",
        "        print(f\"Erro: A coluna '{coluna}' não é do tipo 'object'. Nenhuma transformação será aplicada.\")\n",
        "        return\n",
        "\n",
        "    valores_unicos_na_coluna = df[coluna].dropna().unique()\n",
        "    valores_nao_mapeados = [valor for valor in valores_unicos_na_coluna if valor not in mapa_transformacao]\n",
        "\n",
        "    if valores_nao_mapeados:\n",
        "        print(f\"Erro: Os seguintes valores únicos na coluna '{coluna}' não foram encontrados no mapeamento:\")\n",
        "        print(valores_nao_mapeados)\n",
        "        print(\"A transformação não será realizada pois nem todos os valores possuem um mapeamento.\")\n",
        "        return\n",
        "\n",
        "    df[coluna] = df[coluna].map(mapa_transformacao)\n",
        "    print(f\"Coluna '{coluna}' transformada com sucesso.\")\n",
        "\n",
        "\n",
        "def ler_json_de_url(url: str) -> dict:\n",
        "    \"\"\"\n",
        "    Lê um arquivo JSON de uma URL fornecida.\n",
        "    \"\"\"\n",
        "    try:\n",
        "        resposta = requests.get(url)\n",
        "        resposta.raise_for_status()\n",
        "        dict_dados = resposta.json()\n",
        "        return dict_dados\n",
        "    except Exception as e:\n",
        "        print(f\"Erro ao ler JSON de {url}: {e}\")\n",
        "        return None\n",
        "\n",
        "\n",
        "class MtransGrouper(BaseEstimator, TransformerMixin):\n",
        "    \"\"\"Agrupa as categorias raras de 'mtrans'.\"\"\"\n",
        "    def fit(self, X, y=None):\n",
        "        return self\n",
        "\n",
        "    def transform(self, X):\n",
        "        X_array = np.asarray(X)\n",
        "        X_series = pd.Series(X_array.flatten(), name='mtrans')\n",
        "        mtrans_agrupado = X_series.replace(\n",
        "            ['moto', 'bicicleta', 'caminhando'], 'outros'\n",
        "        )\n",
        "        return mtrans_agrupado.values.reshape(-1, 1)\n",
        "\n",
        "\n",
        "class CalcGrouper(BaseEstimator, TransformerMixin):\n",
        "    \"\"\"Agrupa as categorias raras de 'calc'.\"\"\"\n",
        "    def fit(self, X, y=None):\n",
        "        return self\n",
        "\n",
        "    def transform(self, X):\n",
        "        X_array = np.asarray(X)\n",
        "        X_series = pd.Series(X_array.flatten(), name='calc')\n",
        "        sempre_freq = X_series.replace(\n",
        "            'sempre', 'frequentemente'\n",
        "        )\n",
        "        return sempre_freq.values.reshape(-1, 1)\n",
        "\n",
        "class RoundingTransformer(BaseEstimator, TransformerMixin):\n",
        "    \"\"\"Arredonda os dados sintéticos (ex: 2.45 -> 2)\"\"\"\n",
        "    def fit(self, X, y=None):\n",
        "        return self\n",
        "\n",
        "    def transform(self, X, **kwargs):\n",
        "        return np.round(X).astype(int)\n",
        "\n",
        "\n",
        "#etapa - importacao de dados\n",
        "\n",
        "df = pd.read_csv('https://raw.githubusercontent.com/fiapdatanalytics/tech-challenge4/refs/heads/main/data/Obesity.csv')\n",
        "mapa_colunas = ler_json_de_url('https://raw.githubusercontent.com/fiapdatanalytics/tech-challenge4/refs/heads/main/data/mapa_colunas.json')\n",
        "mapa_valores_colunas = ler_json_de_url('https://raw.githubusercontent.com/fiapdatanalytics/tech-challenge4/refs/heads/main/data/mapa_valores_colunas.json')\n",
        "\n",
        "print(\"DataFrame e mapas JSON carregados com sucesso.\")\n",
        "\n",
        "df_processado = renomear_colunas(df, mapa_colunas)\n",
        "\n",
        "#etapa - pre-processamento\n",
        "\n",
        "# Transformar valores de string\n",
        "if mapa_valores_colunas:\n",
        "    if 'mapeamento_classificacao_peso_corporal' in mapa_valores_colunas:\n",
        "        transformar_valores_string(df_processado, 'classificacao_peso_corporal' , mapa_valores_colunas['mapeamento_classificacao_peso_corporal']['valores_novos_classificacao_peso_corporal'] )\n",
        "    if 'mapeamento_mtrans' in mapa_valores_colunas:\n",
        "         transformar_valores_string(df_processado,'mtrans' , mapa_valores_colunas['mapeamento_mtrans']['valores_novos_mtrans'])\n",
        "    if 'mapeamento_frequencia' in mapa_valores_colunas:\n",
        "        transformar_valores_string(df_processado,'caec' , mapa_valores_colunas['mapeamento_frequencia']['valores_novos_frequencia'])\n",
        "        transformar_valores_string(df_processado,'calc' , mapa_valores_colunas['mapeamento_frequencia']['valores_novos_frequencia'])\n",
        "    if 'mapeamento_genero' in mapa_valores_colunas:\n",
        "        transformar_valores_string(df_processado,'genero' , mapa_valores_colunas['mapeamento_genero']['transformacao_genero'])\n",
        "    if 'mapeamento_sim_nao' in mapa_valores_colunas:\n",
        "        colunas_sim_nao = ['historico_familiar', 'favc', 'fumante', 'scc']\n",
        "        for coluna in colunas_sim_nao:\n",
        "            transformar_valores_string(df_processado, coluna , mapa_valores_colunas['mapeamento_sim_nao']['transformacao_sim_nao'])\n",
        "\n",
        "print(\"Pré-processamentos iniciais aplicados e df_processado criado.\")\n",
        "\n",
        "coluna_alvo = 'classificacao_peso_corporal'\n",
        "\n",
        "# Remover variaveis com vazamento ou risco extremo e colunas originais float\n",
        "variaveis_a_remover_de_X_antes_do_pipeline = [\n",
        "    'peso', 'altura', 'fumante',\n",
        "]\n",
        "\n",
        "X = df_processado.drop(columns=[coluna_alvo] + variaveis_a_remover_de_X_antes_do_pipeline)\n",
        "y = df_processado[coluna_alvo]\n",
        "\n",
        "# Codificar o Alvo (y) de texto para números\n",
        "le = LabelEncoder()\n",
        "y_codificada = le.fit_transform(y)\n",
        "\n",
        "# Separar dados em treino e teste\n",
        "X_treino, X_teste, y_treino, y_teste = train_test_split(\n",
        "    X, y_codificada,\n",
        "    test_size=0.2,\n",
        "    random_state=42,\n",
        "    stratify=y_codificada\n",
        ")\n",
        "\n",
        "print(\"Dados preparados: X, y definidos, y codificado e dividido em treino/teste.\")\n",
        "\n",
        "variaveis_continuas = ['idade']\n",
        "variaveis_bin_nominal = ['genero', 'historico_familiar', 'favc', 'scc']\n",
        "variaveis_multi_nominal = ['mtrans']\n",
        "variaveis_clean_ordenadas = ['caec']\n",
        "variaveis_para_arredondar_e_codificar = ['fcvc', 'ncp', 'ch20', 'faf', 'tue']\n",
        "\n",
        "pipeline_continua = Pipeline(steps=[\n",
        "    ('scaler', StandardScaler())\n",
        "])\n",
        "\n",
        "pipeline_arrredonamento_ordenacao = Pipeline(steps=[\n",
        "    ('rounder', RoundingTransformer()),\n",
        "    ('encoder', OrdinalEncoder(handle_unknown='use_encoded_value', unknown_value=-1))\n",
        "])\n",
        "\n",
        "pipeline_ordenada_limpa = Pipeline(steps=[\n",
        "    ('encoder', OrdinalEncoder(handle_unknown='use_encoded_value', unknown_value=-1))\n",
        "])\n",
        "\n",
        "pipeline_calc = Pipeline(steps=[\n",
        "    ('grouper', CalcGrouper()),\n",
        "    ('encoder', OrdinalEncoder(handle_unknown='use_encoded_value', unknown_value=-1))\n",
        "])\n",
        "\n",
        "pipeline_nominal_bin = Pipeline(steps=[\n",
        "    ('encoder', OrdinalEncoder(handle_unknown='use_encoded_value', unknown_value=-1))\n",
        "])\n",
        "\n",
        "pipeline_nominal_multi = Pipeline(steps=[\n",
        "    ('grouper', MtransGrouper()),\n",
        "    ('encoder', OneHotEncoder(handle_unknown='ignore', drop='first'))\n",
        "])\n",
        "\n",
        "preprocessador = ColumnTransformer(\n",
        "    transformers=[\n",
        "        ('cont', pipeline_continua, variaveis_continuas),\n",
        "        ('arredondada_ord', pipeline_arrredonamento_ordenacao, variaveis_para_arredondar_e_codificar),\n",
        "        ('ord_limpa', pipeline_ordenada_limpa, variaveis_clean_ordenadas),\n",
        "        ('calc_pipe', pipeline_calc, ['calc']),\n",
        "        ('nom_bin', pipeline_nominal_bin, variaveis_bin_nominal),\n",
        "        ('nom_multi', pipeline_nominal_multi, variaveis_multi_nominal)\n",
        "    ],\n",
        "    remainder='drop'\n",
        ")\n",
        "\n",
        "modelo_xgb = XGBClassifier(\n",
        "    objective='multi:softmax',\n",
        "    num_class=7,\n",
        "    n_jobs=-1,\n",
        "    eval_metric='mlogloss',\n",
        "    use_label_encoder=False,\n",
        "    learning_rate= 0.2,\n",
        "    max_depth= 7,\n",
        "    n_estimators= 200,\n",
        "    subsample= 0.8,\n",
        "    random_state=42\n",
        ")\n",
        "\n",
        "pipeline_completa_xgb = Pipeline(steps=[\n",
        "    ('preprocessor', preprocessador),\n",
        "    ('model', modelo_xgb)\n",
        "])\n",
        "\n",
        "print(\"Pipelines de pré-processamento e o modelo XGBoost definidos e combinados no pipeline completo.\")\n",
        "\n",
        "#etapa - treinameto\n",
        "print(\"Iniciando o treinamento do pipeline XGBoost completo...\")\n",
        "\n",
        "pipeline_completa_xgb.fit(X_treino, y_treino)\n",
        "\n",
        "y_prev_xgb = pipeline_completa_xgb.predict(X_teste)\n",
        "xgb_acuracia = accuracy_score(y_teste, y_prev_xgb)\n",
        "print(f\"Acurácia do Pipeline XGBoost: {xgb_acuracia * 100:.2f}%\")\n",
        "\n",
        "nomes_classes = le.classes_\n",
        "print(\"\\nRelatório de Classificação:\")\n",
        "print(classification_report(y_teste, y_prev_xgb, target_names=nomes_classes))\n",
        "\n",
        "print(\"\\nPipeline de pré-processamento e modelagem concluído!\")\n",
        "\n",
        "print(\"Salvando artefatos...\")\n",
        "joblib.dump(pipeline_completa_xgb, 'pipeline_obesidade_completo.joblib')\n",
        "joblib.dump(le, 'label_encoder_xgb.joblib')\n",
        "print(\"Artefatos salvos com sucesso!\")"
      ]
    }
  ]
}